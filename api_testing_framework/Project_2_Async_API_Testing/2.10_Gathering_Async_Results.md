# Lesson 2.10: Gathering Async Results

## A. asyncio.gather() Deep Dive

asyncio.gather() is your main tool for running multiple async operations concurrently.

---

## B. Basic Usage

```python
import asyncio

@pytest.mark.asyncio
async def test_gather_basics(api_client):
    # Run 3 requests concurrently
    r1, r2, r3 = await asyncio.gather(
        api_client.get("/users/1"),
        api_client.get("/users/2"),
        api_client.get("/users/3")
    )
    
    assert all([r1.status_code == 200, r2.status_code == 200, r3.status_code == 200])
```

---

## C. With List of Tasks

```python
@pytest.mark.asyncio
async def test_gather_with_list(api_client):
    tasks = [api_client.get(f"/users/{i}") for i in range(1, 51)]
    responses = await asyncio.gather(*tasks)  # Note the * unpacking
    
    assert len(responses) == 50
    assert all(r.status_code == 200 for r in responses)
```

---

## D. Error Handling with return_exceptions

```python
@pytest.mark.asyncio
async def test_gather_with_errors(api_client):
    results = await asyncio.gather(
        api_client.get("/users/1"),      # Succeeds
        api_client.get("/users/99999"),  # Returns 404
        api_client.get("/users/2"),      # Succeeds
        return_exceptions=True  # Don't fail all if one fails
    )
    
    for result in results:
        if isinstance(result, httpx.Response):
            # Process successful responses
            print(f"Success: {result.status_code}")
        elif isinstance(result, Exception):
            # Handle exceptions
            print(f"Error: {result}")
```

---

## E. Key Takeaways

ðŸ”‘ asyncio.gather() runs coroutines concurrently  
ðŸ”‘ Returns results in same order as inputs  
ðŸ”‘ return_exceptions=True prevents one failure stopping all  
ðŸ”‘ Use * to unpack list of tasks  

Ready for 2.11? ðŸš€

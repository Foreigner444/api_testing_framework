# 3.16 Pydantic with Async httpx

## A. Concept Overview

### What & Why
**Async httpx + Pydantic** is a powerful combination for high-performance API testing. While synchronous code processes one request at a time, async code can handle multiple requests concurrently, dramatically speeding up test suites. Pydantic's validation works seamlessly with async patterns!

### Analogy
Think of sync vs async like **single-line checkout vs. self-checkout lanes**.

**Synchronous (regular httpx)**:
- One cashier, one customer at a time
- Customer 1 â†’ wait â†’ Customer 2 â†’ wait â†’ Customer 3
- Simple but slow

**Asynchronous (httpx.AsyncClient)**:
- Multiple self-checkout lanes
- Customers 1, 2, 3 all checking out simultaneously
- More complex but much faster!

Pydantic validates each "customer" (response) regardless of which lane they used!

---

## B. Code Implementation

### File Path: `tests/test_async_httpx_pydantic.py`

```python
"""Async httpx with Pydantic integration."""
import asyncio
import httpx
import pytest
from typing import List
from models.api_models import User, Post, Comment


# ==================== Basic Async Pattern ====================

@pytest.mark.asyncio
async def test_async_single_user():
    """Test fetching and validating a single user async."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        response = await client.get("/users/1")
        
        assert response.status_code == 200
        
        # Validate with Pydantic
        user = User.model_validate(response.json())
        
        assert user.id == 1
        assert user.name == "Leanne Graham"
        
        print(f"âœ… Async validated user: {user.name}")


# ==================== Concurrent Requests ====================

@pytest.mark.asyncio
async def test_fetch_multiple_users_concurrently():
    """Test fetching multiple users concurrently."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # Create tasks for concurrent requests
        tasks = [
            client.get(f"/users/{user_id}")
            for user_id in range(1, 6)
        ]
        
        # Execute all requests concurrently
        responses = await asyncio.gather(*tasks)
        
        # Validate all responses
        users = [User.model_validate(r.json()) for r in responses]
        
        assert len(users) == 5
        assert all(isinstance(u, User) for u in users)
        assert users[0].id == 1
        assert users[4].id == 5
        
        print(f"âœ… Fetched and validated {len(users)} users concurrently!")
        for user in users:
            print(f"   - {user.name}")


# ==================== Async Helper Function ====================

async def fetch_and_validate(
    client: httpx.AsyncClient,
    endpoint: str,
    model_class
):
    """Helper function to fetch and validate async."""
    response = await client.get(endpoint)
    response.raise_for_status()
    return model_class.model_validate(response.json())


async def fetch_and_validate_list(
    client: httpx.AsyncClient,
    endpoint: str,
    model_class
) -> List:
    """Helper function to fetch and validate list async."""
    response = await client.get(endpoint)
    response.raise_for_status()
    return [model_class.model_validate(item) for item in response.json()]


@pytest.mark.asyncio
async def test_async_helper_functions():
    """Test async helper functions."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # Fetch single user
        user = await fetch_and_validate(client, "/users/1", User)
        assert user.id == 1
        
        # Fetch list of posts
        posts = await fetch_and_validate_list(client, "/posts?userId=1", Post)
        assert len(posts) > 0
        assert all(post.userId == 1 for post in posts)
        
        print(f"âœ… Async helpers work! User: {user.name}, Posts: {len(posts)}")


# ==================== Complex Async Workflow ====================

@pytest.mark.asyncio
async def test_async_workflow():
    """Test complex async workflow with Pydantic validation."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # Step 1: Fetch user
        user = await fetch_and_validate(client, "/users/1", User)
        
        # Step 2: Fetch user's posts concurrently with user's todos
        posts_task = fetch_and_validate_list(client, f"/posts?userId={user.id}", Post)
        
        from models.api_models import Todo
        todos_task = fetch_and_validate_list(client, f"/todos?userId={user.id}", Todo)
        
        # Wait for both concurrently
        posts, todos = await asyncio.gather(posts_task, todos_task)
        
        # Step 3: Fetch comments for first post
        if posts:
            comments = await fetch_and_validate_list(
                client,
                f"/posts/{posts[0].id}/comments",
                Comment
            )
        else:
            comments = []
        
        # All data validated!
        assert user.id == 1
        assert len(posts) > 0
        assert len(todos) > 0
        
        print(f"âœ… Async workflow complete!")
        print(f"   User: {user.name}")
        print(f"   Posts: {len(posts)}")
        print(f"   Todos: {len(todos)}")
        print(f"   Comments on first post: {len(comments)}")


# ==================== Batch Processing ====================

@pytest.mark.asyncio
async def test_batch_process_all_users():
    """Test batch processing all users."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # First, get all users
        response = await client.get("/users")
        user_ids = [u["id"] for u in response.json()]
        
        # Fetch detailed info for each user concurrently
        tasks = [
            fetch_and_validate(client, f"/users/{user_id}", User)
            for user_id in user_ids
        ]
        
        users = await asyncio.gather(*tasks)
        
        assert len(users) == len(user_ids)
        assert all(isinstance(u, User) for u in users)
        
        print(f"âœ… Batch processed {len(users)} users!")


# ==================== Error Handling in Async ====================

@pytest.mark.asyncio
async def test_async_error_handling():
    """Test error handling in async requests."""
    from pydantic import ValidationError
    
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # Valid request
        response1 = await client.get("/users/1")
        user = User.model_validate(response1.json())
        assert user.id == 1
        
        # Invalid endpoint (404)
        response2 = await client.get("/users/999999")
        if response2.status_code == 404:
            print("âœ… Handled 404 gracefully")
        else:
            # Try to validate anyway
            try:
                User.model_validate(response2.json())
            except ValidationError:
                print("âœ… Caught validation error")


# ==================== Async with Timeout ====================

@pytest.mark.asyncio
async def test_async_with_timeout():
    """Test async requests with timeout."""
    timeout = httpx.Timeout(10.0, connect=5.0)
    
    async with httpx.AsyncClient(
        base_url="https://jsonplaceholder.typicode.com",
        timeout=timeout
    ) as client:
        response = await client.get("/users/1")
        user = User.model_validate(response.json())
        
        assert user.id == 1
        print(f"âœ… Async with timeout: {user.name}")


# ==================== Async Fixture ====================

@pytest.fixture
async def async_client():
    """Async client fixture."""
    async with httpx.AsyncClient(
        base_url="https://jsonplaceholder.typicode.com"
    ) as client:
        yield client


@pytest.mark.asyncio
async def test_with_async_fixture(async_client):
    """Test using async client fixture."""
    response = await async_client.get("/users/1")
    user = User.model_validate(response.json())
    
    assert user.id == 1
    print(f"âœ… Async fixture test passed: {user.name}")


# ==================== Performance Comparison ====================

@pytest.mark.asyncio
async def test_sync_vs_async_performance():
    """Compare sync vs async performance."""
    import time
    
    user_ids = list(range(1, 11))  # 10 users
    
    # Synchronous approach
    start_sync = time.time()
    with httpx.Client(base_url="https://jsonplaceholder.typicode.com") as client:
        sync_users = []
        for user_id in user_ids:
            response = client.get(f"/users/{user_id}")
            user = User.model_validate(response.json())
            sync_users.append(user)
    sync_time = time.time() - start_sync
    
    # Asynchronous approach
    start_async = time.time()
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        tasks = [
            fetch_and_validate(client, f"/users/{user_id}", User)
            for user_id in user_ids
        ]
        async_users = await asyncio.gather(*tasks)
    async_time = time.time() - start_async
    
    assert len(sync_users) == len(async_users) == 10
    
    speedup = sync_time / async_time
    
    print(f"\n{'='*60}")
    print(f"Performance Comparison ({len(user_ids)} requests)")
    print(f"{'='*60}")
    print(f"Sync time:  {sync_time:.2f}s")
    print(f"Async time: {async_time:.2f}s")
    print(f"Speedup:    {speedup:.2f}x faster")
    print(f"âœ… Async is significantly faster!")


# ==================== Async Context Manager Pattern ====================

class AsyncAPIClient:
    """Reusable async API client with validation."""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.client = None
    
    async def __aenter__(self):
        self.client = httpx.AsyncClient(base_url=self.base_url)
        await self.client.__aenter__()
        return self
    
    async def __aexit__(self, *args):
        await self.client.__aexit__(*args)
    
    async def get_user(self, user_id: int) -> User:
        """Get and validate a user."""
        response = await self.client.get(f"/users/{user_id}")
        response.raise_for_status()
        return User.model_validate(response.json())
    
    async def get_posts(self, user_id: int) -> List[Post]:
        """Get and validate user's posts."""
        response = await self.client.get(f"/posts?userId={user_id}")
        response.raise_for_status()
        return [Post.model_validate(p) for p in response.json()]


@pytest.mark.asyncio
async def test_async_client_class():
    """Test custom async client class."""
    async with AsyncAPIClient("https://jsonplaceholder.typicode.com") as api:
        # Fetch user
        user = await api.get_user(1)
        assert user.id == 1
        
        # Fetch posts
        posts = await api.get_posts(1)
        assert len(posts) > 0
        
        print(f"âœ… Custom async client works!")
        print(f"   User: {user.name}")
        print(f"   Posts: {len(posts)}")


# ==================== Async List Comprehension ====================

@pytest.mark.asyncio
async def test_async_list_comprehension():
    """Test async list comprehension pattern."""
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        # Fetch users 1-5 concurrently
        users = await asyncio.gather(*[
            fetch_and_validate(client, f"/users/{i}", User)
            for i in range(1, 6)
        ])
        
        assert len(users) == 5
        print(f"âœ… Async list comprehension: {len(users)} users")


# ==================== Semaphore for Rate Limiting ====================

@pytest.mark.asyncio
async def test_async_with_semaphore():
    """Test async requests with rate limiting."""
    semaphore = asyncio.Semaphore(3)  # Max 3 concurrent requests
    
    async def fetch_with_limit(client, user_id):
        async with semaphore:
            return await fetch_and_validate(client, f"/users/{user_id}", User)
    
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        tasks = [fetch_with_limit(client, i) for i in range(1, 11)]
        users = await asyncio.gather(*tasks)
        
        assert len(users) == 10
        print(f"âœ… Rate-limited async: {len(users)} users (max 3 concurrent)")


# ==================== Async Retry Logic ====================

@pytest.mark.asyncio
async def test_async_with_retry():
    """Test async requests with retry logic."""
    async def fetch_with_retry(client, endpoint, model_class, max_retries=3):
        for attempt in range(max_retries):
            try:
                response = await client.get(endpoint)
                response.raise_for_status()
                return model_class.model_validate(response.json())
            except (httpx.HTTPError, Exception) as e:
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(1)  # Wait before retry
    
    async with httpx.AsyncClient(base_url="https://jsonplaceholder.typicode.com") as client:
        user = await fetch_with_retry(client, "/users/1", User)
        assert user.id == 1
        print(f"âœ… Async with retry: {user.name}")
```

---

## C. Connect & Apply

### How to Test It

```bash
# Run async tests
pytest tests/test_async_httpx_pydantic.py -v -s

# Run performance comparison
pytest tests/test_async_httpx_pydantic.py::test_sync_vs_async_performance -v -s
```

### Expected Result

```
tests/test_async_httpx_pydantic.py::test_async_single_user PASSED
âœ… Async validated user: Leanne Graham

tests/test_async_httpx_pydantic.py::test_fetch_multiple_users_concurrently PASSED
âœ… Fetched and validated 5 users concurrently!

tests/test_async_httpx_pydantic.py::test_sync_vs_async_performance PASSED
Performance Comparison (10 requests)
Sync time:  2.34s
Async time: 0.45s
Speedup:    5.20x faster
âœ… Async is significantly faster!

======================== 13 passed in 3.45s =========================
```

---

## D. When to Use Async

| Use Async When | Use Sync When |
|----------------|---------------|
| Making many API calls | Making few API calls |
| Requests are I/O bound | Requests are CPU bound |
| Performance matters | Simplicity matters |
| Testing at scale | Quick one-off tests |

---

## E. What You've Learned

âœ… Using Pydantic with async httpx  
âœ… Concurrent request patterns  
âœ… Async helper functions  
âœ… Complex async workflows  
âœ… Error handling in async  
âœ… Performance benefits  
âœ… Async fixtures  
âœ… Rate limiting with semaphores  
âœ… Retry logic in async  
âœ… Custom async client classes  

---

## F. What's Next?

In **Lesson 3.17 (Response Model Factories)**, we'll learn:
- Building model factories
- Dynamic model generation
- Reusable test data patterns

Almost done! ðŸŽ‰

---

**Ready for the next lesson?**
